import os
import argparse
import json
import hashlib
from   typing import Any
from   PIL import Image
from   PIL.PngImagePlugin import PngInfo

# Define Sampler/Scheduler Information
# Need to be updated whenever new Samplers are added to InvokeAI
sampler_info = {
    "euler": "Euler",
    "euler_ancestral": "Euler Ancestral (Randomizing)",
    "heun": "Heun",
    "heunpp2": "Heun++ 2",
    "dpm_2": "DPM-2 (Diffusion Probabilistic Model)",
    "dpm_2_ancestral": "DPM-2 Ancestral",
    "lms": "LMS (Linear Multi-Step)",
    "dpm_fast": "DPM Fast (DPM without the DPM2 slowdown)",
    "dpm_adaptive": "DPM Adaptive (Dynamic Steps)",
    "dpmpp_2s_ancestral": "DPM++ 2S Ancestral (2nd Order Single-Step)",
    "dpmpp_sde": "DPM++ SDE (Stochastic / randomizing)",
    "dpmpp_sde_gpu": "DPM++ SDE, GPU Seeded",
    "dpmpp_2m": "DPM++ 2M (2nd Order Multi-Step)",
    "dpmpp_2m_sde": "DPM++ 2M SDE",
    "dpmpp_2m_sde_gpu": "DPM++ 2M SDE, GPU Seeded",
    "dpmpp_3m_sde": "DPM++ 3M SDE (3rd Order Multi-Step)",
    "dpmpp_3m_sde_gpu": "DPM++ 3M SDE, GPU Seeded",
    "ddim": "DDIM (Denoising Diffusion Implicit Models)",
    "ddpm": "DDPM (Denoising Diffusion Probabilistic Models)",
    "lcm": "LCM (for LCM models)",
    "uni_pc": "UniPC (Unified Predictor-Corrector)",
    "uni_pc_bh2": "UniPC BH2",
    "euler_cfg_pp": "Euler CFG++ (Manifold-constrained CFG)",
    "euler_ancestral_cfg_pp": "Euler Ancestral CFG++",
    "ipndm": "iPNDM (Improved Pseudo-Numerical methods for Diffusion Models)",
    "ipndm_v": "iPNDM-V (Variable-Step)",
    "deis": "DEIS (Diffusion Exponential Integrator Sampler)"
}

scheduler_info = {
    "normal": "Normal",
    "karras": "Karras",
    "exponential": "Exponential",
    "simple": "Simple",
    "ddim_uniform": "DDIM Uniform",
    "sgm_uniform": "SGM Uniform",
    "turbo": "Turbo (for turbo models)",
    "align_your_steps": "Align Your Steps (NVIDIA)",
    "beta": "Beta"
}

def save_model_hash(basename:str, model_hash:str, hash_cache:Any) -> None:
    # Save calculated model hash to cache so that it can be quickly recalled later
    hash_cache[basename] = model_hash
    with open("./hash_cache.json", "w") as f:
        f.write(json.dumps(hash_cache, indent=4))

# From Automatic1111 source code (./modules/hashes.py)
def calculate_sha256(filename:str) -> str:
    try:
        hash_sha256 = hashlib.sha256()
        blksize = 1024 * 1024
        with open(filename, "rb") as f:
            for chunk in iter(lambda: f.read(blksize), b""):
                hash_sha256.update(chunk)
        return hash_sha256.hexdigest()
    except FileNotFoundError:
        print(f"File not found: {filename}")
        return "NOFILE"

def calculate_shorthash(filename:str, hash_cache:Any) -> str:
    if os.path.basename(filename) in hash_cache:
        shorthash = hash_cache[os.path.basename(filename)]
    else:
        print(f"    Calculating model hash for {os.path.basename(filename)}. This will take a few seconds...", flush=True)
        longhash = calculate_sha256(filename)
        shorthash = longhash[0:10]
        save_model_hash(os.path.basename(filename), shorthash, hash_cache)
    return shorthash

def main() -> None:
    # Initialize configuration
    swarmui_cfg = {}

    # Cache previously calculated hashes so that they can be quickly retrieved
    hash_cache = {}

    parser = argparse.ArgumentParser(description="Convert SwarmUI generated images to Automatic1111 format, for easy upload to Civitai")
    parser.add_argument("filename", type=str, nargs='+', help="PNG file generated by SwarmUI")
    args = parser.parse_args()

    if os.path.exists("./swarmui_cfg.json"):
        with open("./swarmui_cfg.json", "r") as f:
            print("    Config file found", flush=True)
            swarmui_cfg = json.load(f)

    if os.path.exists("./hash_cache.json"):
        with open("./hash_cache.json", "r") as f:
            print("    Hash cache found", flush=True)
            hash_cache = json.load(f)

    file_count = len(args.filename)
    successes  = 0

    for filename in args.filename:
        # Load file and import metadata
        print(f"    Processing file: {filename}", flush=True)
        im_swarm = Image.open(filename)
        im_swarm.load()
        if 'parameters' not in im_swarm.info:
            print(f"        ERROR: {filename} is not generated by SwarmUI! Skipping file...")
            continue
        json_data = json.loads(im_swarm.info['parameters'])['sui_image_params']

        # Build base metadata
        meta_positive = json_data['prompt']
        if 'negativeprompt' in json_data.keys():
            meta_negative = '\nNegative prompt: ' + json_data['negativeprompt']
        meta_steps = '\nSteps: ' + str(json_data['steps'])
        if 'sampler' in json_data.keys():
            meta_sampler = 'Sampler: ' + sampler_info[json_data['sampler']]
        else:
            meta_sampler = ''
        if 'scheduler' in json_data.keys():
            meta_scheduler = 'Schedule type: ' + scheduler_info[json_data['scheduler']]
        else:
            meta_scheduler = ''
        meta_cfg = 'CFG scale: ' + str(json_data['cfgscale'])
        meta_seed = 'Seed: ' + str(json_data['seed'])
        meta_size = 'Size: ' + str(json_data['width']) + 'x' + str(json_data['height'])
        meta_mname = 'Model: ' + json_data['model']

        # Build metadata for checkpoint model
        if 'flux' in meta_mname:
            model_folder = 'unet_model_folder'
        else:
            model_folder = 'model_folder'
        if model_folder in swarmui_cfg:
            model_hash = calculate_shorthash(f"{swarmui_cfg[model_folder]}/{json_data['model']}.safetensors", hash_cache)
            if model_hash != "NOFILE":
                meta_mhash = 'Model hash: ' + model_hash
            else:
                print("        ERROR: Model file not found! Skipping file...", flush=True)
                continue
        else:
            print("        ERROR: Model folder not configured in swarmui_cfg.json! Skipping file...", flush=True)
            continue
        meta_params = [meta_steps, meta_sampler, meta_scheduler, meta_cfg, meta_seed, meta_size, meta_mhash, meta_mname]

        meta_version = 'Version: v1.9.4' # Hard-code to imitate Automatic1111
        meta_params.append(meta_version)
        meta_final = meta_positive + meta_negative + ', '.join(meta_params)

        # Create a PngInfo object to hold the metadata
        metadata = PngInfo()
        metadata.add_text("parameters", meta_final)

        # Save the image with the metadata
        new_filename = os.path.join(os.path.dirname(filename), os.path.basename(filename).split('.')[0] + '_a1111.' + os.path.basename(filename).split('.')[1])
        im_swarm.save(new_filename, pnginfo=metadata)
        print(f"    Converted file saved as: {new_filename}", flush=True)
        successes += 1

    print(f"Work complete. {successes} / {file_count} files successfully converted.")

if __name__ == "__main__":
    main()